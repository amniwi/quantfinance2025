{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3085260-c7ab-4d48-8f3c-4ce78cdea4fe",
   "metadata": {},
   "source": [
    "# Build and Train Long, Short-Term Memory (LSTM) Models\n",
    "Author: Amaris Williams, PhD\n",
    "\n",
    "Date: October 2025\n",
    "\n",
    "This analysis is loosely based on https://doi.org/10.21203/rs.3.rs-7509723/v1\n",
    "### Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96ce665-9cb5-4612-a0c6-4c270f6e3eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 05:07:48.302191: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-07 05:07:49.031023: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-07 05:07:50.162356: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import activations\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "np.random.seed(222)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f395e78-0f70-47c4-a829-25561b78b544",
   "metadata": {},
   "source": [
    "### Load data processed in notebook 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3379c985-6c27-4314-9911-e08539425a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3241, 12)\n",
      "(3241, 11)\n",
      "(3241, 122)\n",
      "(3241, 121)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>log_ret1</th>\n",
       "      <th>sigma_roll1</th>\n",
       "      <th>log_ret5</th>\n",
       "      <th>sigma_roll5</th>\n",
       "      <th>log_ret22</th>\n",
       "      <th>sigma_roll22</th>\n",
       "      <th>log_ret66</th>\n",
       "      <th>log_ret132</th>\n",
       "      <th>sigma_roll132</th>\n",
       "      <th>High</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>^SPX</th>\n",
       "      <th>^SPX</th>\n",
       "      <th>^SPX</th>\n",
       "      <th>^SPX</th>\n",
       "      <th>^SPX</th>\n",
       "      <th>^SPX</th>\n",
       "      <th>^SPX</th>\n",
       "      <th>^SPX</th>\n",
       "      <th>^SPX</th>\n",
       "      <th>^SPX</th>\n",
       "      <th>^SPX</th>\n",
       "      <th>^VIX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-07-14</th>\n",
       "      <td>0.012789</td>\n",
       "      <td>0.453169</td>\n",
       "      <td>0.173274</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.285743</td>\n",
       "      <td>0.089897</td>\n",
       "      <td>0.305275</td>\n",
       "      <td>0.185116</td>\n",
       "      <td>-0.205760</td>\n",
       "      <td>-0.245360</td>\n",
       "      <td>0.357834</td>\n",
       "      <td>0.216518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-15</th>\n",
       "      <td>0.013138</td>\n",
       "      <td>0.456318</td>\n",
       "      <td>0.185703</td>\n",
       "      <td>0.009364</td>\n",
       "      <td>0.240138</td>\n",
       "      <td>0.077959</td>\n",
       "      <td>0.314743</td>\n",
       "      <td>0.185058</td>\n",
       "      <td>-0.207445</td>\n",
       "      <td>-0.250866</td>\n",
       "      <td>0.357734</td>\n",
       "      <td>0.235425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-16</th>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.530982</td>\n",
       "      <td>-0.094402</td>\n",
       "      <td>0.229083</td>\n",
       "      <td>0.036918</td>\n",
       "      <td>0.158570</td>\n",
       "      <td>0.149257</td>\n",
       "      <td>0.194752</td>\n",
       "      <td>-0.295990</td>\n",
       "      <td>-0.336492</td>\n",
       "      <td>0.367955</td>\n",
       "      <td>0.247505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-19</th>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.409912</td>\n",
       "      <td>0.229586</td>\n",
       "      <td>0.046721</td>\n",
       "      <td>0.066108</td>\n",
       "      <td>0.161207</td>\n",
       "      <td>0.169823</td>\n",
       "      <td>0.195809</td>\n",
       "      <td>-0.311151</td>\n",
       "      <td>-0.330827</td>\n",
       "      <td>0.368188</td>\n",
       "      <td>0.236213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-20</th>\n",
       "      <td>0.009671</td>\n",
       "      <td>0.472437</td>\n",
       "      <td>0.279166</td>\n",
       "      <td>0.088928</td>\n",
       "      <td>0.044292</td>\n",
       "      <td>0.153248</td>\n",
       "      <td>0.201585</td>\n",
       "      <td>0.199586</td>\n",
       "      <td>-0.280057</td>\n",
       "      <td>-0.306467</td>\n",
       "      <td>0.369613</td>\n",
       "      <td>0.237526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-25</th>\n",
       "      <td>0.827895</td>\n",
       "      <td>0.415752</td>\n",
       "      <td>0.254942</td>\n",
       "      <td>0.068306</td>\n",
       "      <td>0.042524</td>\n",
       "      <td>0.073869</td>\n",
       "      <td>0.356084</td>\n",
       "      <td>0.110028</td>\n",
       "      <td>0.162576</td>\n",
       "      <td>-0.010178</td>\n",
       "      <td>0.245227</td>\n",
       "      <td>0.139706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-26</th>\n",
       "      <td>0.842343</td>\n",
       "      <td>0.372420</td>\n",
       "      <td>0.294008</td>\n",
       "      <td>0.101563</td>\n",
       "      <td>0.122938</td>\n",
       "      <td>0.096505</td>\n",
       "      <td>0.409116</td>\n",
       "      <td>0.117050</td>\n",
       "      <td>0.205592</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.246651</td>\n",
       "      <td>0.134585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-30</th>\n",
       "      <td>0.842362</td>\n",
       "      <td>0.423846</td>\n",
       "      <td>0.174855</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.122165</td>\n",
       "      <td>0.096502</td>\n",
       "      <td>0.348049</td>\n",
       "      <td>0.099225</td>\n",
       "      <td>0.189916</td>\n",
       "      <td>0.026018</td>\n",
       "      <td>0.245598</td>\n",
       "      <td>0.118566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-31</th>\n",
       "      <td>0.835510</td>\n",
       "      <td>0.599475</td>\n",
       "      <td>0.118316</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.150946</td>\n",
       "      <td>0.084949</td>\n",
       "      <td>0.302797</td>\n",
       "      <td>0.097702</td>\n",
       "      <td>0.203129</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>0.246027</td>\n",
       "      <td>0.119354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01</th>\n",
       "      <td>0.846496</td>\n",
       "      <td>0.440220</td>\n",
       "      <td>0.264943</td>\n",
       "      <td>0.076820</td>\n",
       "      <td>0.246649</td>\n",
       "      <td>0.090549</td>\n",
       "      <td>0.334945</td>\n",
       "      <td>0.102519</td>\n",
       "      <td>0.223064</td>\n",
       "      <td>0.031840</td>\n",
       "      <td>0.247155</td>\n",
       "      <td>0.108718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3241 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Close    Volume  log_ret1 sigma_roll1  log_ret5 sigma_roll5  \\\n",
       "                ^SPX      ^SPX      ^SPX        ^SPX      ^SPX        ^SPX   \n",
       "Date                                                                         \n",
       "2010-07-14  0.012789  0.453169  0.173274    0.001215  0.285743    0.089897   \n",
       "2010-07-15  0.013138  0.456318  0.185703    0.009364  0.240138    0.077959   \n",
       "2010-07-16  0.004710  0.530982 -0.094402    0.229083  0.036918    0.158570   \n",
       "2010-07-19  0.006409  0.409912  0.229586    0.046721  0.066108    0.161207   \n",
       "2010-07-20  0.009671  0.472437  0.279166    0.088928  0.044292    0.153248   \n",
       "...              ...       ...       ...         ...       ...         ...   \n",
       "2023-05-25  0.827895  0.415752  0.254942    0.068306  0.042524    0.073869   \n",
       "2023-05-26  0.842343  0.372420  0.294008    0.101563  0.122938    0.096505   \n",
       "2023-05-30  0.842362  0.423846  0.174855    0.000130  0.122165    0.096502   \n",
       "2023-05-31  0.835510  0.599475  0.118316    0.048000  0.150946    0.084949   \n",
       "2023-06-01  0.846496  0.440220  0.264943    0.076820  0.246649    0.090549   \n",
       "\n",
       "           log_ret22 sigma_roll22 log_ret66 log_ret132 sigma_roll132      High  \n",
       "                ^SPX         ^SPX      ^SPX       ^SPX          ^SPX      ^VIX  \n",
       "Date                                                                            \n",
       "2010-07-14  0.305275     0.185116 -0.205760  -0.245360      0.357834  0.216518  \n",
       "2010-07-15  0.314743     0.185058 -0.207445  -0.250866      0.357734  0.235425  \n",
       "2010-07-16  0.149257     0.194752 -0.295990  -0.336492      0.367955  0.247505  \n",
       "2010-07-19  0.169823     0.195809 -0.311151  -0.330827      0.368188  0.236213  \n",
       "2010-07-20  0.201585     0.199586 -0.280057  -0.306467      0.369613  0.237526  \n",
       "...              ...          ...       ...        ...           ...       ...  \n",
       "2023-05-25  0.356084     0.110028  0.162576  -0.010178      0.245227  0.139706  \n",
       "2023-05-26  0.409116     0.117050  0.205592   0.002151      0.246651  0.134585  \n",
       "2023-05-30  0.348049     0.099225  0.189916   0.026018      0.245598  0.118566  \n",
       "2023-05-31  0.302797     0.097702  0.203129   0.017299      0.246027  0.119354  \n",
       "2023-06-01  0.334945     0.102519  0.223064   0.031840      0.247155  0.108718  \n",
       "\n",
       "[3241 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/home/anw/Documents/Python/Data/\"\n",
    "fs1 = pd.read_csv(str(path) + \"fs1train.csv\", header = [0,1], index_col = 0)\n",
    "fs2 = pd.read_csv(str(path) + \"fs2train.csv\", header = [0,1], index_col = 0)\n",
    "fs3 = pd.read_csv(str(path) + \"fs3train.csv\", header = [0,1], index_col = 0)\n",
    "fs4 = pd.read_csv(str(path) + \"fs4train.csv\", header = [0,1], index_col = 0)\n",
    "y = np.load(str(path) + \"snp500sectorsytrain.npy\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(fs1.shape)\n",
    "print(fs2.shape)\n",
    "print(fs3.shape)\n",
    "print(fs4.shape)\n",
    "fs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c915fd-ba48-4d13-9b87-3a207fb6a136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature Set 1: 12 features\n",
      " Feature Set 2: 11 features\n",
      " Feature Set 3: 122 features\n",
      " Feature Set 4: 121 features\n",
      "(3219, 3)\n"
     ]
    }
   ],
   "source": [
    "# need to convert dfs to 3 dimensions for LSTM model fitting\n",
    "def create_3Darray(Xdata, ydata, lookback):\n",
    "    if len(Xdata) == len(ydata):\n",
    "        X, y = [], []\n",
    "        for i in range(len(Xdata) - lookback):\n",
    "            X.append(Xdata[i:i+lookback])      # sequence of lookback timesteps\n",
    "            y.append(ydata[i+lookback])\n",
    "        return np.array(X), np.array(y)\n",
    "    else:\n",
    "        raise Exception(\"Xdata must be same length as ydata.\")\n",
    "\n",
    "lookback = 22\n",
    "fs1, y = create_3Darray(fs1, y,lookback)\n",
    "fs2, hold = create_3Darray(fs2, np.zeros(len(fs2)), lookback)\n",
    "fs3, hold = create_3Darray(fs3, np.zeros(len(fs3)), lookback)\n",
    "fs4, hold = create_3Darray(fs4, np.zeros(len(fs4)), lookback)\n",
    "del hold\n",
    "\n",
    "print(f' Feature Set 1: {fs1.shape[2]} features')\n",
    "print(f' Feature Set 2: {fs2.shape[2]} features')\n",
    "print(f' Feature Set 3: {fs3.shape[2]} features')\n",
    "print(f' Feature Set 4: {fs4.shape[2]} features')\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510faa0-b7f9-4bd2-a5b4-fcf03a4299f6",
   "metadata": {},
   "source": [
    "## Build the Models\n",
    "\n",
    "Info on LSTMs: https://medium.com/analytics-vidhya/lstms-explained-a-complete-technically-accurate-conceptual-guide-with-keras-2a650327e8f2\n",
    "\n",
    "* Increasing ```units``` relative to number of features allows the model to calculate more relationships between features.\n",
    "    * Some response to a question said the number of units should be a power of 2, such as 32, 64, 128, etc., but did not offer an explanation why.\n",
    "* ```return_sequences``` determines whether all hidden states are returned (```True```) or only the last one (```False```).\n",
    "    * hidden state is the numerical representation of the input data after being passed through a sigmoid function and multiplied by the cell state (defined below), which has been passed through a tangent function.\n",
    "    * should be set to ```True``` for lower levels of a stacked LSTM architecture (passing the results from one LSTM into another).\n",
    "    * should be set to ```True``` for the last layer if you want an output the same dimensions as your input data. If you want a single number or choice as the output, this can be ```False``` on the last layer.\n",
    "* ```return_states``` determines whether all cell states are returned (```True```) or none (```False```).\n",
    "    * cell state is the numerical representation of all past input data after being processed (multiple times) by the \"forget\" weights. The \"older\" input data (data from several steps ago) has been processed more times than \"newer\" input data. Low forget weights (closer to 0) make the old data insignificant (forgotten), and high forget weights (closer to 1) keep the size of old data (remember).\n",
    "    * this value is almost always set to ```False``` (the default).\n",
    "\n",
    "Because of the difference in number of features, the models for feature sets 1 and 2 will have different architectures (fewer units and layers) from the models for feature sets 3 and 4.  \n",
    "\n",
    "### Train and Test the LSTM Model for Feature Set 1\n",
    "Feature Set 1 contains technical features from ^SPX and the high of ^VIX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c82cfbb-8f1d-49e3-b23e-b1f9ae294d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762510071.995214    4315 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9525 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 05:07:53.528048: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2897/2897 - 14s - 5ms/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 2/100\n",
      "2897/2897 - 13s - 4ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 3/100\n",
      "2897/2897 - 7s - 2ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 4/100\n",
      "2897/2897 - 10s - 4ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 5/100\n",
      "2897/2897 - 11s - 4ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 6/100\n",
      "2897/2897 - 11s - 4ms/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 7/100\n",
      "2897/2897 - 11s - 4ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 8/100\n",
      "2897/2897 - 14s - 5ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 9/100\n",
      "2897/2897 - 11s - 4ms/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 10/100\n",
      "2897/2897 - 11s - 4ms/step - loss: 0.0038 - val_loss: 0.0055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c3daf7add30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs1model = Sequential()\n",
    "fs1model.add(keras.Input(shape=(fs1.shape[1], fs1.shape[2])))\n",
    "fs1model.add(LSTM(units=64, return_sequences=True))\n",
    "fs1model.add(LSTM(units=32))\n",
    "# condense the output of the layers into three predictions: fut_sigma_1, fut_sigma_5, and fut_sigma_22\n",
    "fs1model.add(Dense(units=3))  \n",
    "fs1model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "fs1model.fit(fs1, y,  # the training data\n",
    "             epochs=100,  # maximum number of training rounds\n",
    "             batch_size=1,  # want to generate one number for each fut_sigma in testing\n",
    "             verbose=2, \n",
    "             validation_split=0.1,  # % training data set aside for validation\n",
    "             callbacks=es,  # stop early if model not improving anymore\n",
    "             shuffle = False)  # don't shuffle data each epoch, as we have time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d660f6a-7724-4351-aa23-106c3f1270f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 22, 12)\n",
      "(550, 3)\n"
     ]
    }
   ],
   "source": [
    "fs1test = pd.read_csv(str(path) + \"fs1test.csv\", header = [0,1], index_col = 0)\n",
    "ytest = np.load(str(path) + \"snp500sectorsytest.npy\")\n",
    "\n",
    "fs1test, ytest = create_3Darray(fs1test, ytest, lookback)\n",
    "print(fs1test.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58f9f434-f1a2-4da6-9980-aefbc45b6179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 0s - 10ms/step\n",
      "Scaled Mean Squared Error of 1-Day Prediction: 0.004\n",
      "Scaled Mean Squared Error of 5-Day Prediction: 0.006\n",
      "Scaled Mean Squared Error of 22-Day Prediction: 0.013\n"
     ]
    }
   ],
   "source": [
    "guesses = fs1model.predict(fs1test, verbose = 2)\n",
    "guesses = pd.DataFrame(guesses, columns=[\"fut_sigma_1\",\"fut_sigma_5\",\"fut_sigma_22\"])\n",
    "\n",
    "ytestdf = pd.DataFrame(ytest, columns=[\"fut_sigma_1\",\"fut_sigma_5\",\"fut_sigma_22\"])\n",
    "\n",
    "mse1 = np.mean((ytestdf[\"fut_sigma_1\"] - guesses[\"fut_sigma_1\"])**2)\n",
    "mse5 = np.mean((ytestdf[\"fut_sigma_5\"] - guesses[\"fut_sigma_5\"])**2)\n",
    "mse22 = np.mean((ytestdf[\"fut_sigma_22\"] - guesses[\"fut_sigma_22\"])**2)\n",
    "\n",
    "print(f'Scaled Mean Squared Error of 1-Day Prediction: {mse1:.3f}')\n",
    "print(f'Scaled Mean Squared Error of 5-Day Prediction: {mse5:.3f}')\n",
    "print(f'Scaled Mean Squared Error of 22-Day Prediction: {mse22:.3f}')\n",
    "\n",
    "results = pd.DataFrame([mse1,mse5,mse22], columns = [\"fs1_MSE_scaled\"],\n",
    "                       index = [\"1-Day\",\"5-Day\",\"22-Day\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e151d437-f98a-492c-8f30-9cf09d77b359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of 1-Day Prediction: 0.00006\n",
      "Mean Squared Error of 5-Day Prediction: 0.00005\n",
      "Mean Squared Error of 22-Day Prediction: 0.00004\n"
     ]
    }
   ],
   "source": [
    "# Back transform y to un-scaled volatility\n",
    "yscaler = joblib.load(str(path) + 'yscaler.gz')\n",
    "vol = yscaler.inverse_transform(ytest)\n",
    "predvol = yscaler.inverse_transform(guesses)\n",
    "\n",
    "vol = pd.DataFrame(vol, columns=[\"fut_sigma_1\",\"fut_sigma_5\",\"fut_sigma_22\"])\n",
    "predvol = pd.DataFrame(predvol, columns=[\"fut_sigma_1\",\"fut_sigma_5\",\"fut_sigma_22\"])\n",
    "\n",
    "mse1 = np.mean((vol[\"fut_sigma_1\"] - predvol[\"fut_sigma_1\"])**2)\n",
    "mse5 = np.mean((vol[\"fut_sigma_5\"] - predvol[\"fut_sigma_5\"])**2)\n",
    "mse22 = np.mean((vol[\"fut_sigma_22\"] - predvol[\"fut_sigma_22\"])**2)\n",
    "\n",
    "print(f'Mean Squared Error of 1-Day Prediction: {mse1:.5f}')\n",
    "print(f'Mean Squared Error of 5-Day Prediction: {mse5:.5f}')\n",
    "print(f'Mean Squared Error of 22-Day Prediction: {mse22:.5f}')\n",
    "\n",
    "results = pd.concat([results, \n",
    "                     pd.DataFrame([mse1,mse5,mse22], columns = [\"fs1_MSE\"],\n",
    "                                  index = [\"1-Day\",\"5-Day\",\"22-Day\"])],\n",
    "                    axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcbf26c-107a-46fe-a616-e845596fb87e",
   "metadata": {},
   "source": [
    "### Train and Test LSTM for Feature Set 2\n",
    "Feature Set 2 contains technical features from ^SPX and NOT ^VIX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eca04c9c-8dda-424b-9446-38d3680bde35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2897/2897 - 20s - 7ms/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 2/100\n",
      "2897/2897 - 16s - 5ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 3/100\n",
      "2897/2897 - 13s - 5ms/step - loss: 0.0035 - val_loss: 0.0064\n",
      "Epoch 4/100\n",
      "2897/2897 - 15s - 5ms/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 5/100\n",
      "2897/2897 - 9s - 3ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 6/100\n",
      "2897/2897 - 15s - 5ms/step - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 7/100\n",
      "2897/2897 - 16s - 6ms/step - loss: 0.0059 - val_loss: 0.0060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c3daf787d90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs2model = Sequential()\n",
    "fs2model.add(keras.Input(shape=(fs2.shape[1], fs2.shape[2])))\n",
    "fs2model.add(LSTM(units=64, return_sequences=True))\n",
    "fs2model.add(LSTM(units=32))\n",
    "# condense the output of the layers into three predictions: fut_sigma_1, fut_sigma_5, and fut_sigma_22\n",
    "fs2model.add(Dense(units=3))  \n",
    "fs2model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "fs2model.fit(fs2, y,  # the training data\n",
    "             epochs=100,  # maximum number of training rounds\n",
    "             batch_size=1,  # want to generate one number for each fut_sigma in testing\n",
    "             verbose=2, \n",
    "             validation_split=0.1,  # % training data set aside for validation\n",
    "             callbacks=es,  # stop early if model not improving anymore\n",
    "             shuffle = False)  # don't shuffle data each epoch, as we have time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7991df9d-dc3d-48db-a8c5-3590fe9843d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 22, 11)\n",
      "(550, 3)\n"
     ]
    }
   ],
   "source": [
    "fs2test = pd.read_csv(str(path) + \"fs2test.csv\", header = [0,1], index_col = 0)\n",
    "ytest = np.load(str(path) + \"snp500sectorsytest.npy\")\n",
    "\n",
    "fs2test, ytest = create_3Darray(fs2test, ytest, lookback)\n",
    "print(fs2test.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8486e8c0-1e63-402d-a2ad-4b004c445382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 0s - 8ms/step\n",
      "Scaled Mean Squared Error of 1-Day Prediction: 0.004\n",
      "Scaled Mean Squared Error of 5-Day Prediction: 0.009\n",
      "Scaled Mean Squared Error of 22-Day Prediction: 0.017\n"
     ]
    }
   ],
   "source": [
    "guesses = fs2model.predict(fs2test, verbose = 2)\n",
    "guesses = pd.DataFrame(guesses, columns=[\"fut_sigma_1\",\"fut_sigma_5\",\"fut_sigma_22\"])\n",
    "\n",
    "ytestdf = pd.DataFrame(ytest, columns=[\"fut_sigma_1\",\"fut_sigma_5\",\"fut_sigma_22\"])\n",
    "\n",
    "mse1 = np.mean((ytestdf[\"fut_sigma_1\"] - guesses[\"fut_sigma_1\"])**2)\n",
    "mse5 = np.mean((ytestdf[\"fut_sigma_5\"] - guesses[\"fut_sigma_5\"])**2)\n",
    "mse22 = np.mean((ytestdf[\"fut_sigma_22\"] - guesses[\"fut_sigma_22\"])**2)\n",
    "\n",
    "print(f'Scaled Mean Squared Error of 1-Day Prediction: {mse1:.3f}')\n",
    "print(f'Scaled Mean Squared Error of 5-Day Prediction: {mse5:.3f}')\n",
    "print(f'Scaled Mean Squared Error of 22-Day Prediction: {mse22:.3f}')\n",
    "\n",
    "results = pd.concat([results, \n",
    "                     pd.DataFrame([mse1,mse5,mse22], columns = [\"fs2_MSE_scaled\"],\n",
    "                       index = [\"1-Day\",\"5-Day\",\"22-Day\"])],\n",
    "                    axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f54bc7bc-b665-44ee-8279-bdb27a2b1f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of 1-Day Prediction: 0.00007\n",
      "Mean Squared Error of 5-Day Prediction: 0.00007\n",
      "Mean Squared Error of 22-Day Prediction: 0.00006\n"
     ]
    }
   ],
   "source": [
    "# Back transform y to un-scaled volatility\n",
    "predvol = yscaler.inverse_transform(guesses)\n",
    "\n",
    "predvol = pd.DataFrame(predvol, columns=[\"fut_sigma_1\",\"fut_sigma_5\",\"fut_sigma_22\"])\n",
    "\n",
    "mse1 = np.mean((vol[\"fut_sigma_1\"] - predvol[\"fut_sigma_1\"])**2)\n",
    "mse5 = np.mean((vol[\"fut_sigma_5\"] - predvol[\"fut_sigma_5\"])**2)\n",
    "mse22 = np.mean((vol[\"fut_sigma_22\"] - predvol[\"fut_sigma_22\"])**2)\n",
    "\n",
    "print(f'Mean Squared Error of 1-Day Prediction: {mse1:.5f}')\n",
    "print(f'Mean Squared Error of 5-Day Prediction: {mse5:.5f}')\n",
    "print(f'Mean Squared Error of 22-Day Prediction: {mse22:.5f}')\n",
    "\n",
    "results = pd.concat([results, \n",
    "                     pd.DataFrame([mse1,mse5,mse22], columns = [\"fs2_MSE\"],\n",
    "                                  index = [\"1-Day\",\"5-Day\",\"22-Day\"])],\n",
    "                    axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1f1958-08d8-4dcd-b8e4-4099d99a659f",
   "metadata": {},
   "source": [
    "### Train and Test LSTM for Feature Set 3\n",
    "Feature Set 3 contains technical features of each S&P500 sub index and the high of ^VIX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "521ce690-c85e-4f71-a96c-320d76799bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2897/2897 - 13s - 5ms/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 2/100\n",
      "2897/2897 - 12s - 4ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 3/100\n",
      "2897/2897 - 14s - 5ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 4/100\n",
      "2897/2897 - 17s - 6ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 5/100\n",
      "2897/2897 - 15s - 5ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 6/100\n",
      "2897/2897 - 13s - 4ms/step - loss: 0.0052 - val_loss: 0.0047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c3daf7879d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs3model = Sequential()\n",
    "fs3model.add(keras.Input(shape=(fs3.shape[1], fs3.shape[2])))\n",
    "fs3model.add(LSTM(units=256, return_sequences=True))\n",
    "fs3model.add(LSTM(units=128, return_sequences=True))\n",
    "fs3model.add(LSTM(units=64))\n",
    "# condense the output of the layers into three predictions: fut_sigma_1, fut_sigma_5, and fut_sigma_22\n",
    "fs3model.add(Dense(units=3))  \n",
    "fs3model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "fs3model.fit(fs3, y,  # the training data\n",
    "             epochs=100,  # maximum number of training rounds\n",
    "             batch_size=1,  # want to generate one number for each fut_sigma in testing\n",
    "             verbose=2, \n",
    "             validation_split=0.1,  # % training data set aside for validation\n",
    "             callbacks=es,  # stop early if model not improving anymore\n",
    "             shuffle = False)  # don't shuffle data each epoch, as we have time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0204f515-1996-415c-acf9-35a7cea1fbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 22, 122)\n",
      "(550, 3)\n"
     ]
    }
   ],
   "source": [
    "fs3test = pd.read_csv(str(path) + \"fs3test.csv\", header = [0,1], index_col = 0)\n",
    "ytest = np.load(str(path) + \"snp500sectorsytest.npy\")\n",
    "\n",
    "fs3test, ytest = create_3Darray(fs3test, ytest, lookback)\n",
    "print(fs3test.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6f0034a-691f-484d-8a67-98314408adfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 0s - 12ms/step\n",
      "Scaled Mean Squared Error of 1-Day Prediction: 0.004\n",
      "Scaled Mean Squared Error of 5-Day Prediction: 0.007\n",
      "Scaled Mean Squared Error of 22-Day Prediction: 0.013\n"
     ]
    }
   ],
   "source": [
    "guesses = fs3model.predict(fs3test, verbose = 2)\n",
    "guesses = pd.DataFrame(guesses, columns=[\"fut_sigma_1\",\"fut_sigma_5\",\"fut_sigma_22\"])\n",
    "\n",
    "ytestdf = pd.DataFrame(ytest, columns=[\"fut_sigma_1\",\"fut_sigma_5\",\"fut_sigma_22\"])\n",
    "\n",
    "mse1 = np.mean((ytestdf[\"fut_sigma_1\"] - guesses[\"fut_sigma_1\"])**2)\n",
    "mse5 = np.mean((ytestdf[\"fut_sigma_5\"] - guesses[\"fut_sigma_5\"])**2)\n",
    "mse22 = np.mean((ytestdf[\"fut_sigma_22\"] - guesses[\"fut_sigma_22\"])**2)\n",
    "\n",
    "print(f'Scaled Mean Squared Error of 1-Day Prediction: {mse1:.3f}')\n",
    "print(f'Scaled Mean Squared Error of 5-Day Prediction: {mse5:.3f}')\n",
    "print(f'Scaled Mean Squared Error of 22-Day Prediction: {mse22:.3f}')\n",
    "\n",
    "results = pd.concat([results, \n",
    "                     pd.DataFrame([mse1,mse5,mse22], columns = [\"fs3_MSE_scaled\"],\n",
    "                       index = [\"1-Day\",\"5-Day\",\"22-Day\"])],\n",
    "                    axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3e025f7-2dd4-4bab-9db1-5ee6d20657e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of 1-Day Prediction: 0.00007\n",
      "Mean Squared Error of 5-Day Prediction: 0.00005\n",
      "Mean Squared Error of 22-Day Prediction: 0.00004\n"
     ]
    }
   ],
   "source": [
    "# Back transform y to un-scaled volatility\n",
    "predvol = yscaler.inverse_transform(guesses)\n",
    "\n",
    "predvol = pd.DataFrame(predvol, columns=[\"fut_sigma_1\",\"fut_sigma_5\",\"fut_sigma_22\"])\n",
    "\n",
    "mse1 = np.mean((vol[\"fut_sigma_1\"] - predvol[\"fut_sigma_1\"])**2)\n",
    "mse5 = np.mean((vol[\"fut_sigma_5\"] - predvol[\"fut_sigma_5\"])**2)\n",
    "mse22 = np.mean((vol[\"fut_sigma_22\"] - predvol[\"fut_sigma_22\"])**2)\n",
    "\n",
    "print(f'Mean Squared Error of 1-Day Prediction: {mse1:.5f}')\n",
    "print(f'Mean Squared Error of 5-Day Prediction: {mse5:.5f}')\n",
    "print(f'Mean Squared Error of 22-Day Prediction: {mse22:.5f}')\n",
    "\n",
    "results = pd.concat([results, \n",
    "                     pd.DataFrame([mse1,mse5,mse22], columns = [\"fs3_MSE\"],\n",
    "                                  index = [\"1-Day\",\"5-Day\",\"22-Day\"])],\n",
    "                    axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cfbf45-6ab8-461e-8144-cde6c461bfff",
   "metadata": {},
   "source": [
    "### Train and Test LSTM for Feature Set 4\n",
    "Feature Set 4 contains technical features of each S&P500 sub index without ^VIX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ded029c3-1fd5-4ab6-9ad6-77edf1204cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2897/2897 - 13s - 4ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 2/100\n",
      "2897/2897 - 12s - 4ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "2897/2897 - 12s - 4ms/step - loss: 0.0051 - val_loss: 0.0219\n",
      "Epoch 4/100\n",
      "2897/2897 - 12s - 4ms/step - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 5/100\n",
      "2897/2897 - 10s - 4ms/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 6/100\n",
      "2897/2897 - 15s - 5ms/step - loss: 0.0045 - val_loss: 0.0048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c3daf79be10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs4model = Sequential()\n",
    "fs4model.add(keras.Input(shape=(fs4.shape[1], fs4.shape[2])))\n",
    "fs4model.add(LSTM(units=256, return_sequences=True))\n",
    "fs4model.add(LSTM(units=128, return_sequences=True))\n",
    "fs4model.add(LSTM(units=64))\n",
    "# condense the output of the layers into three predictions: fut_sigma_1, fut_sigma_5, and fut_sigma_22\n",
    "fs4model.add(Dense(units=3))  \n",
    "fs4model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "fs4model.fit(fs4, y,  # the training data\n",
    "             epochs=100,  # maximum number of training rounds\n",
    "             batch_size=1,  # want to generate one number for each fut_sigma in testing\n",
    "             verbose=2, \n",
    "             validation_split=0.1,  # % training data set aside for validation\n",
    "             callbacks=es,  # stop early if model not improving anymore\n",
    "             shuffle = False)  # don't shuffle data each epoch, as we have time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ee726df-9573-4259-889d-60f389f1c891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 22, 121)\n",
      "(550, 3)\n"
     ]
    }
   ],
   "source": [
    "fs4test = pd.read_csv(str(path) + \"fs4test.csv\", header = [0,1], index_col = 0)\n",
    "ytest = np.load(str(path) + \"snp500sectorsytest.npy\")\n",
    "\n",
    "fs4test, ytest = create_3Darray(fs4test, ytest, lookback)\n",
    "print(fs4test.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38e49ab0-7c5e-4703-9b4d-20d171bf2d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 0s - 19ms/step\n",
      "Scaled Mean Squared Error of 1-Day Prediction: 0.005\n",
      "Scaled Mean Squared Error of 5-Day Prediction: 0.007\n",
      "Scaled Mean Squared Error of 22-Day Prediction: 0.014\n"
     ]
    }
   ],
   "source": [
    "guesses = fs4model.predict(fs4test, verbose = 2)\n",
    "guesses = pd.DataFrame(guesses, columns=[\"fut_sigma_1\",\"fut_sigma_5\",\"fut_sigma_22\"])\n",
    "\n",
    "ytestdf = pd.DataFrame(ytest, columns=[\"fut_sigma_1\",\"fut_sigma_5\",\"fut_sigma_22\"])\n",
    "\n",
    "mse1 = np.mean((ytestdf[\"fut_sigma_1\"] - guesses[\"fut_sigma_1\"])**2)\n",
    "mse5 = np.mean((ytestdf[\"fut_sigma_5\"] - guesses[\"fut_sigma_5\"])**2)\n",
    "mse22 = np.mean((ytestdf[\"fut_sigma_22\"] - guesses[\"fut_sigma_22\"])**2)\n",
    "\n",
    "print(f'Scaled Mean Squared Error of 1-Day Prediction: {mse1:.3f}')\n",
    "print(f'Scaled Mean Squared Error of 5-Day Prediction: {mse5:.3f}')\n",
    "print(f'Scaled Mean Squared Error of 22-Day Prediction: {mse22:.3f}')\n",
    "\n",
    "results = pd.concat([results, \n",
    "                     pd.DataFrame([mse1,mse5,mse22], columns = [\"fs4_MSE_scaled\"],\n",
    "                       index = [\"1-Day\",\"5-Day\",\"22-Day\"])],\n",
    "                    axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c8883e7-93ef-4685-8e37-cd349e42685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of 1-Day Prediction: 0.00008\n",
      "Mean Squared Error of 5-Day Prediction: 0.00006\n",
      "Mean Squared Error of 22-Day Prediction: 0.00005\n"
     ]
    }
   ],
   "source": [
    "# Back transform y to un-scaled volatility\n",
    "predvol = yscaler.inverse_transform(guesses)\n",
    "\n",
    "predvol = pd.DataFrame(predvol, columns=[\"fut_sigma_1\",\"fut_sigma_5\",\"fut_sigma_22\"])\n",
    "\n",
    "mse1 = np.mean((vol[\"fut_sigma_1\"] - predvol[\"fut_sigma_1\"])**2)\n",
    "mse5 = np.mean((vol[\"fut_sigma_5\"] - predvol[\"fut_sigma_5\"])**2)\n",
    "mse22 = np.mean((vol[\"fut_sigma_22\"] - predvol[\"fut_sigma_22\"])**2)\n",
    "\n",
    "print(f'Mean Squared Error of 1-Day Prediction: {mse1:.5f}')\n",
    "print(f'Mean Squared Error of 5-Day Prediction: {mse5:.5f}')\n",
    "print(f'Mean Squared Error of 22-Day Prediction: {mse22:.5f}')\n",
    "\n",
    "results = pd.concat([results, \n",
    "                     pd.DataFrame([mse1,mse5,mse22], columns = [\"fs4_MSE\"],\n",
    "                                  index = [\"1-Day\",\"5-Day\",\"22-Day\"])],\n",
    "                    axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ff03f0-b29d-4f4c-bebf-1732264a570e",
   "metadata": {},
   "source": [
    "### Which model is best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffc83dd1-c613-4fd5-9cee-d82bb15080bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fs1_MSE_scaled</th>\n",
       "      <th>fs1_MSE</th>\n",
       "      <th>fs2_MSE_scaled</th>\n",
       "      <th>fs2_MSE</th>\n",
       "      <th>fs3_MSE_scaled</th>\n",
       "      <th>fs3_MSE</th>\n",
       "      <th>fs4_MSE_scaled</th>\n",
       "      <th>fs4_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-Day</th>\n",
       "      <td>0.003977</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.005097</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-Day</th>\n",
       "      <td>0.005733</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.006796</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22-Day</th>\n",
       "      <td>0.012844</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.012908</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.014268</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fs1_MSE_scaled   fs1_MSE  fs2_MSE_scaled   fs2_MSE  fs3_MSE_scaled  \\\n",
       "1-Day         0.003977  0.000065        0.004493  0.000073        0.004242   \n",
       "5-Day         0.005733  0.000046        0.008551  0.000068        0.006796   \n",
       "22-Day        0.012844  0.000041        0.017267  0.000055        0.012908   \n",
       "\n",
       "         fs3_MSE  fs4_MSE_scaled   fs4_MSE  \n",
       "1-Day   0.000069        0.005097  0.000083  \n",
       "5-Day   0.000054        0.007011  0.000056  \n",
       "22-Day  0.000041        0.014268  0.000046  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da903e3f-4149-4060-b033-6f41cea87092",
   "metadata": {},
   "source": [
    "Feature Set 1 yielded the lowest mean squared error at 2 of 3 time windows among all feature sets. It appears including ^VIX in the feature set improves prediction of actual, observed volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8551f72-1059-4613-b3e5-cbfc1ff2a3a9",
   "metadata": {},
   "source": [
    "### Save the best model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91a5f729-c054-4bfc-ad7e-071626b098ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs1model.save(str(path) + 'fs1model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbac86c-4bb1-4d2c-8d46-1d2057f4b43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
